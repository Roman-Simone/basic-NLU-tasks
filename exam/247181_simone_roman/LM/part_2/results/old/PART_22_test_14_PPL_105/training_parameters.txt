PART_22

Hidden Size: 650
Embedding Size: 650
Learning Rate: 1.0625
Clip: 5
Vocabulary Length: 10001
Number of Epochs: 13
Best Dev PPL: 100.78483203894042
Best Test PPL: 105.05508404326885
Batch Size Train: 32
Batch Size Dev: 64
Batch Size Test: 64
Optimizer: SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 8.5
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
Model: LM_LSTM_DROP(
  (embedding): Embedding(10001, 650, padding_idx=0)
  (emb_dropout): VariationalDropout()
  (lstm): LSTM(650, 650, batch_first=True)
  (output): Linear(in_features=650, out_features=10001, bias=True)
  (out_dropout): VariationalDropout()
)
